==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
TESTING AdaptiveAvgPool2d((1, 1)) 
==> Building model..
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,728
       BatchNorm2d-2           [-1, 64, 32, 32]             128
            Conv2d-3           [-1, 64, 32, 32]          36,864
       BatchNorm2d-4           [-1, 64, 32, 32]             128
            Conv2d-5           [-1, 64, 32, 32]          36,864
       BatchNorm2d-6           [-1, 64, 32, 32]             128
ModifiedBasicBlock-7           [-1, 64, 32, 32]               0
            Conv2d-8           [-1, 64, 32, 32]          36,864
       BatchNorm2d-9           [-1, 64, 32, 32]             128
           Conv2d-10           [-1, 64, 32, 32]          36,864
      BatchNorm2d-11           [-1, 64, 32, 32]             128
ModifiedBasicBlock-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]          36,864
      BatchNorm2d-14           [-1, 64, 32, 32]             128
           Conv2d-15           [-1, 64, 32, 32]          36,864
      BatchNorm2d-16           [-1, 64, 32, 32]             128
ModifiedBasicBlock-17           [-1, 64, 32, 32]               0
           Conv2d-18           [-1, 64, 32, 32]          36,864
      BatchNorm2d-19           [-1, 64, 32, 32]             128
           Conv2d-20           [-1, 64, 32, 32]          36,864
      BatchNorm2d-21           [-1, 64, 32, 32]             128
ModifiedBasicBlock-22           [-1, 64, 32, 32]               0
           Conv2d-23          [-1, 128, 16, 16]          73,728
      BatchNorm2d-24          [-1, 128, 16, 16]             256
           Conv2d-25          [-1, 128, 16, 16]         147,456
      BatchNorm2d-26          [-1, 128, 16, 16]             256
           Conv2d-27          [-1, 128, 16, 16]           8,192
      BatchNorm2d-28          [-1, 128, 16, 16]             256
ModifiedBasicBlock-29          [-1, 128, 16, 16]               0
           Conv2d-30          [-1, 128, 16, 16]         147,456
      BatchNorm2d-31          [-1, 128, 16, 16]             256
           Conv2d-32          [-1, 128, 16, 16]         147,456
      BatchNorm2d-33          [-1, 128, 16, 16]             256
ModifiedBasicBlock-34          [-1, 128, 16, 16]               0
           Conv2d-35          [-1, 128, 16, 16]         147,456
      BatchNorm2d-36          [-1, 128, 16, 16]             256
           Conv2d-37          [-1, 128, 16, 16]         147,456
      BatchNorm2d-38          [-1, 128, 16, 16]             256
ModifiedBasicBlock-39          [-1, 128, 16, 16]               0
           Conv2d-40          [-1, 128, 16, 16]         147,456
      BatchNorm2d-41          [-1, 128, 16, 16]             256
           Conv2d-42          [-1, 128, 16, 16]         147,456
      BatchNorm2d-43          [-1, 128, 16, 16]             256
ModifiedBasicBlock-44          [-1, 128, 16, 16]               0
           Conv2d-45            [-1, 256, 8, 8]         294,912
      BatchNorm2d-46            [-1, 256, 8, 8]             512
           Conv2d-47            [-1, 256, 8, 8]         589,824
      BatchNorm2d-48            [-1, 256, 8, 8]             512
           Conv2d-49            [-1, 256, 8, 8]          32,768
      BatchNorm2d-50            [-1, 256, 8, 8]             512
ModifiedBasicBlock-51            [-1, 256, 8, 8]               0
           Conv2d-52            [-1, 256, 8, 8]         589,824
      BatchNorm2d-53            [-1, 256, 8, 8]             512
           Conv2d-54            [-1, 256, 8, 8]         589,824
      BatchNorm2d-55            [-1, 256, 8, 8]             512
ModifiedBasicBlock-56            [-1, 256, 8, 8]               0
           Conv2d-57            [-1, 256, 8, 8]         589,824
      BatchNorm2d-58            [-1, 256, 8, 8]             512
           Conv2d-59            [-1, 256, 8, 8]         589,824
      BatchNorm2d-60            [-1, 256, 8, 8]             512
ModifiedBasicBlock-61            [-1, 256, 8, 8]               0
AdaptiveAvgPool2d-62            [-1, 256, 1, 1]               0
           Linear-63                   [-1, 10]           2,570
       PoolResNet-64                   [-1, 10]               0
================================================================
Total params: 4,697,162
Trainable params: 4,697,162
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.63
Params size (MB): 17.92
Estimated Total Size (MB): 36.56
----------------------------------------------------------------

Epoch: 0
Loss: 1.993 | Acc: 27.056% (13528/50000)
Loss: 1.852 | Acc: 32.710% (3271/10000)
Saving..
BEST ACCURACY: 32.71 ON EPOCH 0

Epoch: 1
Loss: 1.480 | Acc: 44.846% (22423/50000)
Loss: 1.450 | Acc: 46.970% (4697/10000)
Saving..
BEST ACCURACY: 46.97 ON EPOCH 1

Epoch: 2
Loss: 1.190 | Acc: 56.894% (28447/50000)
Loss: 1.109 | Acc: 60.960% (6096/10000)
Saving..
BEST ACCURACY: 60.96 ON EPOCH 2

Epoch: 3
Loss: 0.956 | Acc: 66.064% (33032/50000)
Loss: 1.187 | Acc: 61.770% (6177/10000)
Saving..
BEST ACCURACY: 61.77 ON EPOCH 3

Epoch: 4
Loss: 0.810 | Acc: 71.672% (35836/50000)
Loss: 1.080 | Acc: 64.950% (6495/10000)
Saving..
BEST ACCURACY: 64.95 ON EPOCH 4

Epoch: 5
Loss: 0.684 | Acc: 76.200% (38100/50000)
Loss: 0.864 | Acc: 71.070% (7107/10000)
Saving..
BEST ACCURACY: 71.07 ON EPOCH 5

Epoch: 6
Loss: 0.605 | Acc: 79.196% (39598/50000)
Loss: 0.748 | Acc: 74.580% (7458/10000)
Saving..
BEST ACCURACY: 74.58 ON EPOCH 6

Epoch: 7
Loss: 0.548 | Acc: 81.122% (40561/50000)
Loss: 0.658 | Acc: 78.330% (7833/10000)
Saving..
BEST ACCURACY: 78.33 ON EPOCH 7

Epoch: 8
Loss: 0.508 | Acc: 82.682% (41341/50000)
Loss: 0.618 | Acc: 79.590% (7959/10000)
Saving..
BEST ACCURACY: 79.59 ON EPOCH 8

Epoch: 9
Loss: 0.483 | Acc: 83.516% (41758/50000)
Loss: 0.658 | Acc: 77.950% (7795/10000)
Saving..

Epoch: 10
Loss: 0.460 | Acc: 84.078% (42039/50000)
Loss: 0.585 | Acc: 80.720% (8072/10000)
Saving..
BEST ACCURACY: 80.72 ON EPOCH 10

Epoch: 11
Loss: 0.444 | Acc: 84.756% (42378/50000)
Loss: 0.596 | Acc: 80.560% (8056/10000)
Saving..

Epoch: 12
Loss: 0.426 | Acc: 85.312% (42656/50000)
Loss: 0.544 | Acc: 81.750% (8175/10000)
Saving..
BEST ACCURACY: 81.75 ON EPOCH 12

Epoch: 13
Loss: 0.414 | Acc: 85.792% (42896/50000)
Loss: 0.653 | Acc: 78.350% (7835/10000)
Saving..

Epoch: 14
Loss: 0.406 | Acc: 86.058% (43029/50000)
Loss: 0.584 | Acc: 79.910% (7991/10000)
Saving..

Epoch: 15
Loss: 0.394 | Acc: 86.460% (43230/50000)
Loss: 1.125 | Acc: 71.120% (7112/10000)
Saving..

Epoch: 16
Loss: 0.387 | Acc: 86.690% (43345/50000)
Loss: 0.542 | Acc: 82.170% (8217/10000)
Saving..
BEST ACCURACY: 82.17 ON EPOCH 16

Epoch: 17
Loss: 0.371 | Acc: 87.176% (43588/50000)
Loss: 0.631 | Acc: 80.050% (8005/10000)
Saving..

Epoch: 18
Loss: 0.366 | Acc: 87.530% (43765/50000)
Loss: 0.545 | Acc: 81.990% (8199/10000)
Saving..

Epoch: 19
Loss: 0.359 | Acc: 87.656% (43828/50000)
Loss: 0.518 | Acc: 83.120% (8312/10000)
Saving..
BEST ACCURACY: 83.12 ON EPOCH 19

Epoch: 20
Loss: 0.355 | Acc: 87.664% (43832/50000)
Loss: 0.452 | Acc: 84.570% (8457/10000)
Saving..
BEST ACCURACY: 84.57 ON EPOCH 20

Epoch: 21
Loss: 0.346 | Acc: 88.184% (44092/50000)
Loss: 0.539 | Acc: 82.700% (8270/10000)
Saving..

Epoch: 22
Loss: 0.343 | Acc: 88.306% (44153/50000)
Loss: 0.396 | Acc: 86.640% (8664/10000)
Saving..
BEST ACCURACY: 86.64 ON EPOCH 22

Epoch: 23
Loss: 0.337 | Acc: 88.408% (44204/50000)
Loss: 0.403 | Acc: 86.170% (8617/10000)
Saving..

Epoch: 24
Loss: 0.327 | Acc: 88.650% (44325/50000)
Loss: 0.576 | Acc: 81.850% (8185/10000)
Saving..

Epoch: 25
Loss: 0.329 | Acc: 88.752% (44376/50000)
Loss: 0.528 | Acc: 82.840% (8284/10000)
Saving..

Epoch: 26
Loss: 0.328 | Acc: 88.744% (44372/50000)
Loss: 0.448 | Acc: 84.560% (8456/10000)
Saving..

Epoch: 27
Loss: 0.320 | Acc: 88.870% (44435/50000)
Loss: 0.507 | Acc: 83.720% (8372/10000)
Saving..

Epoch: 28
Loss: 0.323 | Acc: 88.856% (44428/50000)
Loss: 0.521 | Acc: 82.720% (8272/10000)
Saving..

Epoch: 29
Loss: 0.314 | Acc: 89.290% (44645/50000)
Loss: 0.442 | Acc: 85.240% (8524/10000)
Saving..

Epoch: 30
Loss: 0.310 | Acc: 89.440% (44720/50000)
Loss: 0.529 | Acc: 82.710% (8271/10000)
Saving..

Epoch: 31
Loss: 0.313 | Acc: 89.246% (44623/50000)
Loss: 0.433 | Acc: 85.520% (8552/10000)
Saving..

Epoch: 32
Loss: 0.308 | Acc: 89.338% (44669/50000)
Loss: 0.701 | Acc: 79.220% (7922/10000)
Saving..

Epoch: 33
Loss: 0.301 | Acc: 89.766% (44883/50000)
Loss: 0.530 | Acc: 83.210% (8321/10000)
Saving..

Epoch: 34
Loss: 0.303 | Acc: 89.616% (44808/50000)
Loss: 0.402 | Acc: 86.350% (8635/10000)
Saving..

Epoch: 35
Loss: 0.302 | Acc: 89.638% (44819/50000)
Loss: 0.443 | Acc: 85.460% (8546/10000)
Saving..

Epoch: 36
Loss: 0.300 | Acc: 89.714% (44857/50000)
Loss: 0.417 | Acc: 86.180% (8618/10000)
Saving..

Epoch: 37
Loss: 0.291 | Acc: 90.086% (45043/50000)
Loss: 0.439 | Acc: 85.750% (8575/10000)
Saving..

Epoch: 38
Loss: 0.293 | Acc: 89.984% (44992/50000)
Loss: 0.478 | Acc: 83.630% (8363/10000)
Saving..

Epoch: 39
Loss: 0.294 | Acc: 89.836% (44918/50000)
Loss: 0.431 | Acc: 85.550% (8555/10000)
Saving..

Epoch: 40
Loss: 0.285 | Acc: 90.298% (45149/50000)
Loss: 0.373 | Acc: 87.420% (8742/10000)
Saving..
BEST ACCURACY: 87.42 ON EPOCH 40

Epoch: 41
Loss: 0.283 | Acc: 90.440% (45220/50000)
Loss: 0.478 | Acc: 84.090% (8409/10000)
Saving..

Epoch: 42
Loss: 0.283 | Acc: 90.266% (45133/50000)
Loss: 0.461 | Acc: 85.210% (8521/10000)
Saving..

Epoch: 43
Loss: 0.282 | Acc: 90.388% (45194/50000)
Loss: 0.485 | Acc: 84.240% (8424/10000)
Saving..

Epoch: 44
Loss: 0.283 | Acc: 90.482% (45241/50000)
Loss: 0.429 | Acc: 86.040% (8604/10000)
Saving..

Epoch: 45
Loss: 0.275 | Acc: 90.566% (45283/50000)
Loss: 0.488 | Acc: 83.850% (8385/10000)
Saving..

Epoch: 46
Loss: 0.280 | Acc: 90.392% (45196/50000)
Loss: 0.580 | Acc: 80.870% (8087/10000)
Saving..

Epoch: 47
Loss: 0.273 | Acc: 90.700% (45350/50000)
Loss: 0.515 | Acc: 84.510% (8451/10000)
Saving..

Epoch: 48
Loss: 0.270 | Acc: 90.700% (45350/50000)
Loss: 0.494 | Acc: 83.270% (8327/10000)
Saving..

Epoch: 49
Loss: 0.267 | Acc: 90.796% (45398/50000)
Loss: 0.419 | Acc: 86.150% (8615/10000)
Saving..

Epoch: 50
Loss: 0.267 | Acc: 90.832% (45416/50000)
Loss: 0.394 | Acc: 86.670% (8667/10000)
Saving..

Epoch: 51
Loss: 0.264 | Acc: 90.970% (45485/50000)
Loss: 0.657 | Acc: 79.780% (7978/10000)
Saving..

Epoch: 52
Loss: 0.265 | Acc: 90.884% (45442/50000)
Loss: 0.464 | Acc: 84.980% (8498/10000)
Saving..

Epoch: 53
Loss: 0.266 | Acc: 90.868% (45434/50000)
Loss: 0.564 | Acc: 83.320% (8332/10000)
Saving..

Epoch: 54
Loss: 0.258 | Acc: 91.174% (45587/50000)
Loss: 0.436 | Acc: 85.560% (8556/10000)
Saving..

Epoch: 55
Loss: 0.257 | Acc: 91.122% (45561/50000)
Loss: 0.375 | Acc: 87.450% (8745/10000)
Saving..
BEST ACCURACY: 87.45 ON EPOCH 55

Epoch: 56
Loss: 0.255 | Acc: 91.242% (45621/50000)
Loss: 0.428 | Acc: 85.880% (8588/10000)
Saving..

Epoch: 57
Loss: 0.256 | Acc: 91.302% (45651/50000)
Loss: 0.560 | Acc: 82.260% (8226/10000)
Saving..

Epoch: 58
Loss: 0.252 | Acc: 91.322% (45661/50000)
Loss: 0.456 | Acc: 85.130% (8513/10000)
Saving..

Epoch: 59
Loss: 0.251 | Acc: 91.312% (45656/50000)
Loss: 0.407 | Acc: 86.860% (8686/10000)
Saving..

Epoch: 60
Loss: 0.245 | Acc: 91.676% (45838/50000)
Loss: 0.633 | Acc: 80.690% (8069/10000)
Saving..

Epoch: 61
Loss: 0.248 | Acc: 91.264% (45632/50000)
Loss: 0.428 | Acc: 86.600% (8660/10000)
Saving..

Epoch: 62
Loss: 0.245 | Acc: 91.516% (45758/50000)
Loss: 0.413 | Acc: 86.380% (8638/10000)
Saving..

Epoch: 63
Loss: 0.242 | Acc: 91.652% (45826/50000)
Loss: 0.425 | Acc: 86.470% (8647/10000)
Saving..

Epoch: 64
Loss: 0.238 | Acc: 91.854% (45927/50000)
Loss: 0.367 | Acc: 87.500% (8750/10000)
Saving..
BEST ACCURACY: 87.5 ON EPOCH 64

Epoch: 65
Loss: 0.235 | Acc: 91.922% (45961/50000)
Loss: 0.404 | Acc: 87.040% (8704/10000)
Saving..

Epoch: 66
Loss: 0.239 | Acc: 91.794% (45897/50000)
Loss: 0.337 | Acc: 88.890% (8889/10000)
Saving..
BEST ACCURACY: 88.89 ON EPOCH 66

Epoch: 67
Loss: 0.227 | Acc: 92.310% (46155/50000)
Loss: 0.537 | Acc: 83.660% (8366/10000)
Saving..

Epoch: 68
Loss: 0.242 | Acc: 91.670% (45835/50000)
Loss: 0.566 | Acc: 82.730% (8273/10000)
Saving..

Epoch: 69
Loss: 0.224 | Acc: 92.418% (46209/50000)
Loss: 0.459 | Acc: 85.330% (8533/10000)
Saving..

Epoch: 70
Loss: 0.225 | Acc: 92.278% (46139/50000)
Loss: 0.374 | Acc: 88.060% (8806/10000)
Saving..

Epoch: 71
Loss: 0.233 | Acc: 91.988% (45994/50000)
Loss: 0.425 | Acc: 86.610% (8661/10000)
Saving..

Epoch: 72
Loss: 0.221 | Acc: 92.370% (46185/50000)
Loss: 0.438 | Acc: 85.770% (8577/10000)
Saving..

Epoch: 73
Loss: 0.225 | Acc: 92.272% (46136/50000)
Loss: 0.382 | Acc: 87.310% (8731/10000)
Saving..

Epoch: 74
Loss: 0.213 | Acc: 92.582% (46291/50000)
Loss: 0.624 | Acc: 81.450% (8145/10000)
Saving..

Epoch: 75
Loss: 0.220 | Acc: 92.502% (46251/50000)
Loss: 0.424 | Acc: 85.980% (8598/10000)
Saving..

Epoch: 76
Loss: 0.214 | Acc: 92.804% (46402/50000)
Loss: 0.386 | Acc: 87.520% (8752/10000)
Saving..

Epoch: 77
Loss: 0.211 | Acc: 92.880% (46440/50000)
Loss: 0.324 | Acc: 89.280% (8928/10000)
Saving..
BEST ACCURACY: 89.28 ON EPOCH 77

Epoch: 78
Loss: 0.218 | Acc: 92.608% (46304/50000)
Loss: 0.486 | Acc: 85.140% (8514/10000)
Saving..

Epoch: 79
Loss: 0.207 | Acc: 92.912% (46456/50000)
Loss: 0.400 | Acc: 87.420% (8742/10000)
Saving..

Epoch: 80
Loss: 0.212 | Acc: 92.724% (46362/50000)
Loss: 0.351 | Acc: 88.790% (8879/10000)
Saving..

Epoch: 81
Loss: 0.206 | Acc: 92.892% (46446/50000)
Loss: 0.377 | Acc: 87.520% (8752/10000)
Saving..

Epoch: 82
Loss: 0.204 | Acc: 92.976% (46488/50000)
Loss: 0.394 | Acc: 87.210% (8721/10000)
Saving..

Epoch: 83
Loss: 0.199 | Acc: 93.144% (46572/50000)
Loss: 0.335 | Acc: 88.810% (8881/10000)
Saving..

Epoch: 84
Loss: 0.198 | Acc: 93.202% (46601/50000)
Loss: 0.365 | Acc: 88.440% (8844/10000)
Saving..

Epoch: 85
Loss: 0.195 | Acc: 93.182% (46591/50000)
Loss: 0.331 | Acc: 89.350% (8935/10000)
Saving..
BEST ACCURACY: 89.35 ON EPOCH 85

Epoch: 86
Loss: 0.198 | Acc: 93.142% (46571/50000)
Loss: 0.389 | Acc: 87.330% (8733/10000)
Saving..

Epoch: 87
Loss: 0.190 | Acc: 93.542% (46771/50000)
Loss: 0.398 | Acc: 87.570% (8757/10000)
Saving..

Epoch: 88
Loss: 0.188 | Acc: 93.592% (46796/50000)
Loss: 0.381 | Acc: 88.050% (8805/10000)
Saving..

Epoch: 89
Loss: 0.188 | Acc: 93.556% (46778/50000)
Loss: 0.332 | Acc: 89.150% (8915/10000)
Saving..

Epoch: 90
Loss: 0.185 | Acc: 93.686% (46843/50000)
Loss: 0.428 | Acc: 86.400% (8640/10000)
Saving..

Epoch: 91
Loss: 0.185 | Acc: 93.598% (46799/50000)
Loss: 0.363 | Acc: 88.380% (8838/10000)
Saving..

Epoch: 92
Loss: 0.180 | Acc: 93.858% (46929/50000)
Loss: 0.337 | Acc: 89.330% (8933/10000)
Saving..

Epoch: 93
Loss: 0.175 | Acc: 93.934% (46967/50000)
Loss: 0.430 | Acc: 86.340% (8634/10000)
Saving..

Epoch: 94
Loss: 0.177 | Acc: 94.056% (47028/50000)
Loss: 0.341 | Acc: 88.990% (8899/10000)
Saving..

Epoch: 95
Loss: 0.179 | Acc: 93.866% (46933/50000)
Loss: 0.345 | Acc: 88.940% (8894/10000)
Saving..

Epoch: 96
Loss: 0.166 | Acc: 94.334% (47167/50000)
Loss: 0.363 | Acc: 88.640% (8864/10000)
Saving..

Epoch: 97
Loss: 0.168 | Acc: 94.198% (47099/50000)
Loss: 0.356 | Acc: 88.680% (8868/10000)
Saving..

Epoch: 98
Loss: 0.164 | Acc: 94.278% (47139/50000)
Loss: 0.360 | Acc: 88.940% (8894/10000)
Saving..

Epoch: 99
Loss: 0.165 | Acc: 94.328% (47164/50000)
Loss: 0.343 | Acc: 89.350% (8935/10000)
Saving..

Epoch: 100
Loss: 0.160 | Acc: 94.580% (47290/50000)
Loss: 0.407 | Acc: 87.170% (8717/10000)
Saving..

Epoch: 101
Loss: 0.154 | Acc: 94.732% (47366/50000)
Loss: 0.302 | Acc: 89.990% (8999/10000)
Saving..
BEST ACCURACY: 89.99 ON EPOCH 101

Epoch: 102
Loss: 0.157 | Acc: 94.640% (47320/50000)
Loss: 0.344 | Acc: 88.790% (8879/10000)
Saving..

Epoch: 103
Loss: 0.154 | Acc: 94.770% (47385/50000)
Loss: 0.466 | Acc: 85.980% (8598/10000)
Saving..

Epoch: 104
Loss: 0.150 | Acc: 94.908% (47454/50000)
Loss: 0.279 | Acc: 91.050% (9105/10000)
Saving..
BEST ACCURACY: 91.05 ON EPOCH 104

Epoch: 105
Loss: 0.148 | Acc: 94.930% (47465/50000)
Loss: 0.562 | Acc: 84.190% (8419/10000)
Saving..

Epoch: 106
Loss: 0.145 | Acc: 95.112% (47556/50000)
Loss: 0.315 | Acc: 89.990% (8999/10000)
Saving..

Epoch: 107
Loss: 0.139 | Acc: 95.324% (47662/50000)
Loss: 0.331 | Acc: 89.840% (8984/10000)
Saving..

Epoch: 108
Loss: 0.135 | Acc: 95.492% (47746/50000)
Loss: 0.349 | Acc: 89.570% (8957/10000)
Saving..

Epoch: 109
Loss: 0.142 | Acc: 95.162% (47581/50000)
Loss: 0.328 | Acc: 89.570% (8957/10000)
Saving..

Epoch: 110
Loss: 0.129 | Acc: 95.558% (47779/50000)
Loss: 0.311 | Acc: 90.470% (9047/10000)
Saving..

Epoch: 111
Loss: 0.133 | Acc: 95.492% (47746/50000)
Loss: 0.297 | Acc: 90.690% (9069/10000)
Saving..

Epoch: 112
Loss: 0.128 | Acc: 95.670% (47835/50000)
Loss: 0.372 | Acc: 88.750% (8875/10000)
Saving..

Epoch: 113
Loss: 0.129 | Acc: 95.640% (47820/50000)
Loss: 0.352 | Acc: 89.020% (8902/10000)
Saving..

Epoch: 114
Loss: 0.123 | Acc: 95.786% (47893/50000)
Loss: 0.360 | Acc: 88.630% (8863/10000)
Saving..

Epoch: 115
Loss: 0.120 | Acc: 95.934% (47967/50000)
Loss: 0.351 | Acc: 89.600% (8960/10000)
Saving..

Epoch: 116
Loss: 0.122 | Acc: 95.842% (47921/50000)
Loss: 0.366 | Acc: 88.890% (8889/10000)
Saving..

Epoch: 117
Loss: 0.115 | Acc: 96.070% (48035/50000)
Loss: 0.272 | Acc: 91.340% (9134/10000)
Saving..
BEST ACCURACY: 91.34 ON EPOCH 117

Epoch: 118
Loss: 0.116 | Acc: 96.098% (48049/50000)
Loss: 0.282 | Acc: 91.240% (9124/10000)
Saving..

Epoch: 119
Loss: 0.111 | Acc: 96.150% (48075/50000)
Loss: 0.361 | Acc: 88.750% (8875/10000)
Saving..

Epoch: 120
Loss: 0.108 | Acc: 96.320% (48160/50000)
Loss: 0.263 | Acc: 91.830% (9183/10000)
Saving..
BEST ACCURACY: 91.83 ON EPOCH 120

Epoch: 121
Loss: 0.102 | Acc: 96.570% (48285/50000)
Loss: 0.285 | Acc: 91.290% (9129/10000)
Saving..

Epoch: 122
Loss: 0.103 | Acc: 96.522% (48261/50000)
Loss: 0.395 | Acc: 88.860% (8886/10000)
Saving..

Epoch: 123
Loss: 0.101 | Acc: 96.616% (48308/50000)
Loss: 0.268 | Acc: 91.710% (9171/10000)
Saving..

Epoch: 124
Loss: 0.096 | Acc: 96.882% (48441/50000)
Loss: 0.314 | Acc: 90.800% (9080/10000)
Saving..

Epoch: 125
Loss: 0.088 | Acc: 97.108% (48554/50000)
Loss: 0.332 | Acc: 89.930% (8993/10000)
Saving..

Epoch: 126
Loss: 0.093 | Acc: 96.870% (48435/50000)
Loss: 0.302 | Acc: 90.770% (9077/10000)
Saving..

Epoch: 127
Loss: 0.090 | Acc: 96.960% (48480/50000)
Loss: 0.273 | Acc: 91.920% (9192/10000)
Saving..
BEST ACCURACY: 91.92 ON EPOCH 127

Epoch: 128
Loss: 0.088 | Acc: 97.072% (48536/50000)
Loss: 0.266 | Acc: 91.720% (9172/10000)
Saving..

Epoch: 129
Loss: 0.084 | Acc: 97.290% (48645/50000)
Loss: 0.290 | Acc: 91.190% (9119/10000)
Saving..

Epoch: 130
Loss: 0.083 | Acc: 97.200% (48600/50000)
Loss: 0.293 | Acc: 91.070% (9107/10000)
Saving..

Epoch: 131
Loss: 0.078 | Acc: 97.368% (48684/50000)
Loss: 0.305 | Acc: 91.130% (9113/10000)
Saving..

Epoch: 132
Loss: 0.073 | Acc: 97.578% (48789/50000)
Loss: 0.304 | Acc: 91.040% (9104/10000)
Saving..

Epoch: 133
Loss: 0.077 | Acc: 97.450% (48725/50000)
Loss: 0.282 | Acc: 91.620% (9162/10000)
Saving..

Epoch: 134
Loss: 0.071 | Acc: 97.676% (48838/50000)
Loss: 0.250 | Acc: 92.500% (9250/10000)
Saving..
BEST ACCURACY: 92.5 ON EPOCH 134

Epoch: 135
Loss: 0.069 | Acc: 97.746% (48873/50000)
Loss: 0.266 | Acc: 91.940% (9194/10000)
Saving..

Epoch: 136
Loss: 0.060 | Acc: 98.082% (49041/50000)
Loss: 0.268 | Acc: 92.120% (9212/10000)
Saving..

Epoch: 137
Loss: 0.061 | Acc: 98.110% (49055/50000)
Loss: 0.275 | Acc: 92.290% (9229/10000)
Saving..

Epoch: 138
Loss: 0.061 | Acc: 98.014% (49007/50000)
Loss: 0.302 | Acc: 91.630% (9163/10000)
Saving..

Epoch: 139
Loss: 0.058 | Acc: 98.046% (49023/50000)
Loss: 0.267 | Acc: 92.280% (9228/10000)
Saving..

Epoch: 140
Loss: 0.050 | Acc: 98.444% (49222/50000)
Loss: 0.305 | Acc: 91.200% (9120/10000)
Saving..

Epoch: 141
Loss: 0.058 | Acc: 98.198% (49099/50000)
Loss: 0.278 | Acc: 91.980% (9198/10000)
Saving..

Epoch: 142
Loss: 0.046 | Acc: 98.610% (49305/50000)
Loss: 0.289 | Acc: 92.070% (9207/10000)
Saving..

Epoch: 143
Loss: 0.047 | Acc: 98.560% (49280/50000)
Loss: 0.250 | Acc: 93.040% (9304/10000)
Saving..
BEST ACCURACY: 93.04 ON EPOCH 143

Epoch: 144
Loss: 0.044 | Acc: 98.590% (49295/50000)
Loss: 0.276 | Acc: 92.110% (9211/10000)
Saving..

Epoch: 145
Loss: 0.042 | Acc: 98.662% (49331/50000)
Loss: 0.249 | Acc: 92.760% (9276/10000)
Saving..

Epoch: 146
Loss: 0.034 | Acc: 99.030% (49515/50000)
Loss: 0.234 | Acc: 93.210% (9321/10000)
Saving..
BEST ACCURACY: 93.21 ON EPOCH 146

Epoch: 147
Loss: 0.035 | Acc: 98.970% (49485/50000)
Loss: 0.241 | Acc: 93.050% (9305/10000)
Saving..

Epoch: 148
Loss: 0.034 | Acc: 98.932% (49466/50000)
Loss: 0.249 | Acc: 92.910% (9291/10000)
Saving..

Epoch: 149
Loss: 0.035 | Acc: 98.972% (49486/50000)
Loss: 0.247 | Acc: 92.650% (9265/10000)
Saving..

Epoch: 150
Loss: 0.030 | Acc: 99.134% (49567/50000)
Loss: 0.234 | Acc: 93.280% (9328/10000)
Saving..
BEST ACCURACY: 93.28 ON EPOCH 150

Epoch: 151
Loss: 0.026 | Acc: 99.294% (49647/50000)
Loss: 0.234 | Acc: 93.450% (9345/10000)
Saving..
BEST ACCURACY: 93.45 ON EPOCH 151

Epoch: 152
Loss: 0.024 | Acc: 99.306% (49653/50000)
Loss: 0.218 | Acc: 93.830% (9383/10000)
Saving..
BEST ACCURACY: 93.83 ON EPOCH 152

Epoch: 153
Loss: 0.021 | Acc: 99.436% (49718/50000)
Loss: 0.218 | Acc: 93.940% (9394/10000)
Saving..
BEST ACCURACY: 93.94 ON EPOCH 153

Epoch: 154
Loss: 0.019 | Acc: 99.518% (49759/50000)
Loss: 0.203 | Acc: 93.910% (9391/10000)
Saving..

Epoch: 155
Loss: 0.015 | Acc: 99.632% (49816/50000)
Loss: 0.212 | Acc: 94.130% (9413/10000)
Saving..
BEST ACCURACY: 94.13 ON EPOCH 155

Epoch: 156
Loss: 0.011 | Acc: 99.784% (49892/50000)
Loss: 0.215 | Acc: 93.980% (9398/10000)
Saving..

Epoch: 157
Loss: 0.015 | Acc: 99.612% (49806/50000)
Loss: 0.211 | Acc: 94.160% (9416/10000)
Saving..
BEST ACCURACY: 94.16 ON EPOCH 157

Epoch: 158
Loss: 0.012 | Acc: 99.716% (49858/50000)
Loss: 0.192 | Acc: 94.580% (9458/10000)
Saving..
BEST ACCURACY: 94.58 ON EPOCH 158

Epoch: 159
Loss: 0.009 | Acc: 99.818% (49909/50000)
Loss: 0.192 | Acc: 94.650% (9465/10000)
Saving..
BEST ACCURACY: 94.65 ON EPOCH 159

Epoch: 160
Loss: 0.008 | Acc: 99.836% (49918/50000)
Loss: 0.193 | Acc: 94.500% (9450/10000)
Saving..

Epoch: 161
Loss: 0.008 | Acc: 99.868% (49934/50000)
Loss: 0.181 | Acc: 94.720% (9472/10000)
Saving..
BEST ACCURACY: 94.72 ON EPOCH 161

Epoch: 162
Loss: 0.006 | Acc: 99.918% (49959/50000)
Loss: 0.173 | Acc: 95.250% (9525/10000)
Saving..
BEST ACCURACY: 95.25 ON EPOCH 162

Epoch: 163
Loss: 0.004 | Acc: 99.958% (49979/50000)
Loss: 0.167 | Acc: 95.220% (9522/10000)
Saving..

Epoch: 164
Loss: 0.004 | Acc: 99.962% (49981/50000)
Loss: 0.173 | Acc: 95.040% (9504/10000)
Saving..

Epoch: 165
Loss: 0.003 | Acc: 99.974% (49987/50000)
Loss: 0.176 | Acc: 94.980% (9498/10000)
Saving..

Epoch: 166
Loss: 0.003 | Acc: 99.994% (49997/50000)
Loss: 0.170 | Acc: 95.140% (9514/10000)
Saving..

Epoch: 167
Loss: 0.003 | Acc: 99.984% (49992/50000)
Loss: 0.171 | Acc: 95.270% (9527/10000)
Saving..
BEST ACCURACY: 95.27 ON EPOCH 167

Epoch: 168
Loss: 0.003 | Acc: 99.982% (49991/50000)
Loss: 0.163 | Acc: 95.490% (9549/10000)
Saving..
BEST ACCURACY: 95.49 ON EPOCH 168

Epoch: 169
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.164 | Acc: 95.380% (9538/10000)
Saving..

Epoch: 170
Loss: 0.002 | Acc: 99.996% (49998/50000)
Loss: 0.161 | Acc: 95.220% (9522/10000)
Saving..

Epoch: 171
Loss: 0.002 | Acc: 99.996% (49998/50000)
Loss: 0.164 | Acc: 95.260% (9526/10000)
Saving..

Epoch: 172
Loss: 0.002 | Acc: 99.990% (49995/50000)
Loss: 0.158 | Acc: 95.500% (9550/10000)
Saving..
BEST ACCURACY: 95.5 ON EPOCH 172

Epoch: 173
Loss: 0.002 | Acc: 99.994% (49997/50000)
Loss: 0.156 | Acc: 95.430% (9543/10000)
Saving..

Epoch: 174
Loss: 0.002 | Acc: 99.994% (49997/50000)
Loss: 0.157 | Acc: 95.500% (9550/10000)
Saving..

Epoch: 175
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.154 | Acc: 95.530% (9553/10000)
Saving..
BEST ACCURACY: 95.53 ON EPOCH 175

Epoch: 176
Loss: 0.002 | Acc: 99.996% (49998/50000)
Loss: 0.155 | Acc: 95.590% (9559/10000)
Saving..
BEST ACCURACY: 95.59 ON EPOCH 176

Epoch: 177
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.155 | Acc: 95.480% (9548/10000)
Saving..

Epoch: 178
Loss: 0.002 | Acc: 99.996% (49998/50000)
Loss: 0.153 | Acc: 95.450% (9545/10000)
Saving..

Epoch: 179
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.153 | Acc: 95.570% (9557/10000)
Saving..

Epoch: 180
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.154 | Acc: 95.570% (9557/10000)
Saving..

Epoch: 181
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.155 | Acc: 95.680% (9568/10000)
Saving..
BEST ACCURACY: 95.68 ON EPOCH 181

Epoch: 182
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.153 | Acc: 95.610% (9561/10000)
Saving..

Epoch: 183
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.154 | Acc: 95.640% (9564/10000)
Saving..

Epoch: 184
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.152 | Acc: 95.590% (9559/10000)
Saving..

Epoch: 185
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.600% (9560/10000)
Saving..

Epoch: 186
Loss: 0.002 | Acc: 99.996% (49998/50000)
Loss: 0.152 | Acc: 95.630% (9563/10000)
Saving..

Epoch: 187
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.152 | Acc: 95.560% (9556/10000)
Saving..

Epoch: 188
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.152 | Acc: 95.590% (9559/10000)
Saving..

Epoch: 189
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.600% (9560/10000)
Saving..

Epoch: 190
Loss: 0.002 | Acc: 99.996% (49998/50000)
Loss: 0.151 | Acc: 95.640% (9564/10000)
Saving..

Epoch: 191
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.152 | Acc: 95.550% (9555/10000)
Saving..

Epoch: 192
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.590% (9559/10000)
Saving..

Epoch: 193
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.590% (9559/10000)
Saving..

Epoch: 194
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.610% (9561/10000)
Saving..

Epoch: 195
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.660% (9566/10000)
Saving..

Epoch: 196
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.620% (9562/10000)
Saving..

Epoch: 197
Loss: 0.002 | Acc: 99.998% (49999/50000)
Loss: 0.150 | Acc: 95.660% (9566/10000)
Saving..

Epoch: 198
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.151 | Acc: 95.610% (9561/10000)
Saving..

Epoch: 199
Loss: 0.002 | Acc: 100.000% (50000/50000)
Loss: 0.152 | Acc: 95.610% (9561/10000)
Saving..
